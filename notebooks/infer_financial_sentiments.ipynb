{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321b4ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3be8cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"financial_data_kaggle.csv\",\n",
    "                 names=[\"sentiment\", \"text\"],\n",
    "                 encoding=\"utf-8\", encoding_errors=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d3d888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7404f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     2879\n",
       "positive    1363\n",
       "negative     604\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adf5c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ = df[\"sentiment\"].map(lambda x: x in {\"positive\", \"negative\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9c461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's deal with neutrals later, probably can assign them to 0.5\n",
    "df = df[filter_].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de887d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    1363\n",
       "negative     604\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2ff3d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_ = {\n",
    "    \"positive\": 1,\n",
    "    \"negative\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a074ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"] = df[\"sentiment\"].map(mapping_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a06651de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(input_text: str) -> str:\n",
    "    s = input_text.lower()\n",
    "    s = (s\n",
    "         .replace('<br />', ' ')\n",
    "         .replace('`', \"'\")\n",
    "         .replace('´',\"'\")\n",
    "         .replace(\" '\", ' \"')\n",
    "         .replace(\"-\", \" - \")\n",
    "         .replace(\"/\", \" \")\n",
    "         .replace(\"_\", \" \")\n",
    "        )\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "747faacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].map(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7530f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_func = nltk.word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59a2cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_sequences(corpus, vocabulary_index, tok_func):\n",
    "    corpus_tokens = []\n",
    "    for text in corpus:\n",
    "        tokens = tok_func(text)\n",
    "        indicies = [vocabulary_index.get(x, 1) for x in tokens]\n",
    "        corpus_tokens.append(indicies)\n",
    "    return corpus_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6814d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('vocab_index.json', 'r') as fp:\n",
    "    vocabulary_index = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4facb47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('glove_word_averaging_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a846ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6163edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = texts_to_sequences(corpus, vocabulary_index, tokenizer_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f5182be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = tf.keras.preprocessing.sequence.pad_sequences(X_eval, maxlen=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1bc042e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "776e11af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"preds\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a4040e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>the international electronic industry company ...</td>\n",
       "      <td>0.673213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>with the new production plant the company woul...</td>\n",
       "      <td>0.715204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>according to the company \"s updated strategy f...</td>\n",
       "      <td>0.194155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>financing of aspocomp \"s growth aspocomp is ag...</td>\n",
       "      <td>0.487524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>for the last quarter of 2010 , componenta \"s n...</td>\n",
       "      <td>0.817759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text     preds\n",
       "2          0  the international electronic industry company ...  0.673213\n",
       "3          1  with the new production plant the company woul...  0.715204\n",
       "4          1  according to the company \"s updated strategy f...  0.194155\n",
       "5          1  financing of aspocomp \"s growth aspocomp is ag...  0.487524\n",
       "6          1  for the last quarter of 2010 , componenta \"s n...  0.817759"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b65f8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pred_discrete\"] = (df[\"preds\"] > 0.5).map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ce0fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.5892221657346213\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy is\", np.mean(df[\"pred_discrete\"] == df[\"sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19655803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 2ms/step\n",
      "accuracy is 0.87936\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./imdb_full_dataset_test.csv\")\n",
    "\n",
    "corpus = df_test[\"text\"]\n",
    "X_eval = texts_to_sequences(corpus, vocabulary_index, tokenizer_func)\n",
    "X_eval = tf.keras.preprocessing.sequence.pad_sequences(X_eval, maxlen=512)\n",
    "predictions = model.predict(X_eval)\n",
    "\n",
    "df_test[\"preds\"] = predictions\n",
    "\n",
    "df_test[\"pred_discrete\"] = (df_test[\"preds\"] > 0.5).map(int)\n",
    "\n",
    "print(\"accuracy is\", np.mean(df_test[\"pred_discrete\"] == df_test[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ec0609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('glove_lstm_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "184966ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 4ms/step\n",
      "accuracy is 0.86532\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./imdb_full_dataset_test.csv\")\n",
    "\n",
    "corpus = df_test[\"text\"]\n",
    "X_eval = texts_to_sequences(corpus, vocabulary_index, tokenizer_func)\n",
    "X_eval = tf.keras.preprocessing.sequence.pad_sequences(X_eval, maxlen=256)\n",
    "predictions = model.predict(X_eval)\n",
    "\n",
    "df_test[\"preds\"] = predictions\n",
    "\n",
    "df_test[\"pred_discrete\"] = (df_test[\"preds\"] > 0.5).map(int)\n",
    "\n",
    "print(\"accuracy is\", np.mean(df_test[\"pred_discrete\"] == df_test[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12af80d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 4ms/step\n",
      "accuracy is 0.5683782409761058\n"
     ]
    }
   ],
   "source": [
    "corpus = df[\"text\"]\n",
    "X_eval = texts_to_sequences(corpus, vocabulary_index, tokenizer_func)\n",
    "X_eval = tf.keras.preprocessing.sequence.pad_sequences(X_eval, maxlen=256)\n",
    "predictions = model.predict(X_eval)\n",
    "df[\"preds\"] = predictions\n",
    "df[\"pred_discrete\"] = (df[\"preds\"] > 0.5).map(int)\n",
    "print(\"accuracy is\", np.mean(df[\"pred_discrete\"] == df[\"sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download from dropbox link I shared:\n",
    "# and exctract using tar -xvf fname.tar.gz \n",
    "# should point the load to the directory coming\n",
    "# out of the untar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2ea97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load('bert_trained_on_imdb.saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bf3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(lst, batch_size=16): \n",
    "    indx_ = 0\n",
    "    \n",
    "    while indx_ < len(lst):\n",
    "        yield lst[indx_: indx_ + batch_size]\n",
    "        indx_ += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c790fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def bert_batch_predict(corpus):\n",
    "    batches = list(batchify(corpus, batch_size=32))\n",
    "    \n",
    "    all_preds = []\n",
    "    \n",
    "    for batch in tqdm(batches): \n",
    "        preds = model.__call__(batch, training=False)\n",
    "        all_preds.append(preds.numpy().ravel())\n",
    "    \n",
    "    return np.concatenate(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f85c014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:34<00:00,  1.79it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = bert_batch_predict(list(df[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6b4737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bert_preds\"] = all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96b24ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bert_preds_discrete\"] = (df[\"bert_preds\"] > 0.5).map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2134f2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert model accuracy is 0.668530757498729\n"
     ]
    }
   ],
   "source": [
    "print(\"bert model accuracy is\", np.mean(df[\"bert_preds_discrete\"] == df[\"sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c74f49cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb\t\t\t\t\t   glove.6B.zip\r\n",
      "aclImdb_v1.tar.gz\t\t\t   glove_lstm_model.keras\r\n",
      "baseline.ipynb\t\t\t\t   glove_vecs.bin\r\n",
      "bert_trained_on_imdb.saved_model\t   glove_word_averaging_model.h5\r\n",
      "bert_trained_on_imdb.saved_model.tar.gz    glove_word_averaging_model.keras\r\n",
      "bert_train_on_imdb.ipynb\t\t   imdb_full_dataset.csv\r\n",
      "CEO CFO Remarks.py\t\t\t   imdb_full_dataset_test.csv\r\n",
      "earning_call_train.zip\t\t\t   imdb_full_dataset_train.csv\r\n",
      "Earning Call Transcript - Training Data    infer_financial_sentiments.ipynb\r\n",
      "Earning Call Transcript - Validation Data  random_word_averaging_model.keras\r\n",
      "earning_call_validation.zip\t\t   random_word_lstm_model.keras\r\n",
      "eps_logistic_regression.ipynb\t\t   run_model_on_our_data.ipynb\r\n",
      "financial_data_kaggle.csv\t\t   train-00000-of-00001.parquet\r\n",
      "financial_labels.csv\t\t\t   using_glove.ipynb\r\n",
      "glove.42B.300d.txt\t\t\t   vocab_index.json\r\n",
      "glove.42B.300d.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b740abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./imdb_full_dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aea2a8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [07:31<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"text\"] = df[\"text\"].map(preprocess_text)\n",
    "all_preds = bert_batch_predict(list(df[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ddb13e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert model accuracy is 0.91776\n"
     ]
    }
   ],
   "source": [
    "df[\"bert_preds\"] = all_preds\n",
    "df[\"bert_preds_discrete\"] = (df[\"bert_preds\"] > 0.5).map(int)\n",
    "print(\"bert model accuracy is\", np.mean(df[\"bert_preds_discrete\"] == df[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31e25c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "training_earning_call_transcript_structured = json.load(\n",
    "    open(\"../extract_data_scripts/training_earning_call_transcript_structured.json\")\n",
    ")\n",
    "validation_earning_call_transcript_structured = json.load(\n",
    "    open(\"../extract_data_scripts/validation_earning_call_transcript_structured.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9a4c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "# from collections import Counter\n",
    "\n",
    "# part_counter = Counter()\n",
    "# for k, v in training_earning_call_transcript_structured.items():\n",
    "#     try:\n",
    "#         paragraphs = v['paragraphs']\n",
    "#         participants = v['participants']\n",
    "#         part_counter.update(participants.values())\n",
    "#     except:\n",
    "#         print(f\"couldn't find paragraph or participant for {k}\")\n",
    "#         counter += 1\n",
    "#         continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c0933ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e08f6adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the one we will consider are\n",
    "\n",
    "participant_canonical = {\n",
    "    'Chief Financial Officer': 'CFO',\n",
    "    'CFO': 'CFO',\n",
    "    'President and CEO': 'CEO',\n",
    "    'President and Chief Executive Officer': 'CEO',\n",
    "    'CEO': 'CEO',\n",
    "    'President': 'CEO',\n",
    "    'Chairman and Chief Executive Officer': 'CEO',\n",
    "    'Executive Vice President and Chief Financial Officer': 'CFO',\n",
    "    'President & Chief Executive Officer': 'CEO',\n",
    "    'EVP and CFO': 'CFO',\n",
    "    'President & CEO': 'CEO',\n",
    "    'Chairman and CEO': 'CEO',\n",
    "    'Senior Vice President and Chief Financial Officer': 'CFO',\n",
    "    'EVP & CFO': 'CFO',\n",
    "    'Executive Vice President & Chief Financial Officer': 'CFO',\n",
    "    'Chairman & Chief Executive Officer': 'CEO',\n",
    "    'Chairman, President and Chief Executive Officer': 'CEO',\n",
    "    'SVP and CFO': 'CFO',\n",
    "    'Chairman & CEO': 'CEO',\n",
    "    'Chairman, President & CEO': 'CEO',\n",
    "    'Senior Vice President & Chief Financial Officer': 'CFO',\n",
    "    'Chief Executive Officer and President': 'CEO',\n",
    "    'Chairman, President and CEO': 'CEO',\n",
    "    'President, Chief Executive Officer': 'CEO',\n",
    "    'Chair and Chief Executive Officer': 'CEO',\n",
    "    'Senior Executive Vice President and Chief Financial Officer': 'CFO',\n",
    "    'Group Chief Financial Officer': 'CFO',\n",
    "    'President, CEO': 'CEO',\n",
    "    'Executive Vice President, Chief Financial Officer': 'CFO',\n",
    "    'SVP & CFO': 'CFO',\n",
    "    'Vice President and Chief Financial Officer': 'CFO',\n",
    "    'Chief Financial Officer and Treasurer': 'CFO',\n",
    "    'Executive Vice President, Chief Financial Officer and Treasurer': 'CFO',\n",
    "    'EVP and Chief Financial Officer': 'CFO',\n",
    "    'CEO and President': 'CEO',\n",
    "    'Chief Financial Officer and Chief Operating Officer': 'CFO',\n",
    "    'Chairman, President & Chief Executive Officer': 'CEO',\n",
    "    'Chairman, President, and CEO': 'CEO',\n",
    "    'CEO & Director': 'CEO',\n",
    "    'Chief Executive': 'CEO',\n",
    "    'SVP & Chief Financial Officer': 'CFO',\n",
    "    'Chief Execuitve Officer': 'CEO',\n",
    "    'Head of Financial Control and Capital': 'CFO',\n",
    "    'Senior Managing Corporate Officer and Group Chief Financial': 'CFO',\n",
    "    'Acting Chief Financial Officer': 'CFO',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc8b6277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonicalize(x):\n",
    "    if 'CEO' in x:\n",
    "        return 'CEO'\n",
    "    \n",
    "    if 'Chief Executive Officer' in x:\n",
    "        return 'CEO'\n",
    "    \n",
    "    if 'CFO' in x:\n",
    "        return 'CFO'\n",
    "    \n",
    "    # Group Chief Financial\n",
    "    \n",
    "    return participant_canonical.get(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7092011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_batch_predict(corpus):\n",
    "    batches = list(batchify(corpus, batch_size=32))\n",
    "    \n",
    "    all_preds = []\n",
    "    \n",
    "    for batch in batches: \n",
    "        preds = model.__call__(batch, training=False)\n",
    "        all_preds.append(preds.numpy().ravel())\n",
    "    \n",
    "    return np.concatenate(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0caf199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 270/683 [06:50<13:05,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ceo cfo speak found for FJTSF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 288/683 [07:16<09:09,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ceo cfo speak found for GPI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 370/683 [09:15<08:59,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ceo cfo speak found for LTOUF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 476/683 [11:34<04:22,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ceo cfo speak found for PCRFY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 536/683 [12:55<04:01,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ceo cfo speak found for SSNLF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 542/683 [12:59<02:12,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ceo cfo speak found for SARTF\n",
      "no ceo cfo speak found for SDMHF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 594/683 [14:11<02:48,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ceo cfo speak found for TTDKY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 680/683 [16:31<00:05,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ceo cfo speak found for ELF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 683/683 [16:35<00:00,  1.46s/it]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for k, v in tqdm(training_earning_call_transcript_structured.items()):\n",
    "    try:\n",
    "        paragraphs = v['paragraphs']\n",
    "        participants = v['participants']\n",
    "        \n",
    "        if not participants:\n",
    "            # print(f\"participant empty for {k}\")\n",
    "            counter += 1\n",
    "            continue\n",
    "        \n",
    "        v['_participants'] = {k: canonicalize(v) for k, v in participants.items()}\n",
    "        \n",
    "        if 'CEO' not in v['_participants']:\n",
    "            if 'CFO' not in v['_participants']:\n",
    "                counter += 1\n",
    "                continue\n",
    "                # print(f\"couldn't find CEO/CFO participant for {k}\")\n",
    "                # print(participants)\n",
    "        \n",
    "        ceo_paragraphs = []\n",
    "        cfo_paragraphs = []\n",
    "        for item in paragraphs:\n",
    "            speaker = item['speaker']\n",
    "            if v['_participants'].get(speaker) == 'CEO':\n",
    "                ceo_paragraphs.append(item['text'])\n",
    "            if v['_participants'].get(speaker) == 'CFO':\n",
    "                cfo_paragraphs.append(item['text'])\n",
    "        \n",
    "        if len(ceo_paragraphs) == 0:\n",
    "            if len(cfo_paragraphs) == 0:\n",
    "                counter += 1\n",
    "                print(f\"no ceo cfo speak found for {k}\")\n",
    "                continue\n",
    "                \n",
    "        v['_ceo_paragraphs'] = ceo_paragraphs\n",
    "        v['_cfo_paragraphs'] = cfo_paragraphs\n",
    "        \n",
    "        if len(ceo_paragraphs) > 0:\n",
    "            x = bert_batch_predict(ceo_paragraphs)\n",
    "            x = [float(v) for v in x]\n",
    "            v['_ceo_sentiments'] = x\n",
    "            v['_ceo_avg_sentiment'] = float(np.mean(x))\n",
    "            v['_ceo_median_sentiment'] = float(np.median(x))\n",
    "            v['_ceo_min_sentiment'] = float(np.min(x))\n",
    "            v['_ceo_max_sentiment'] = float(np.max(x))\n",
    "        \n",
    "        if len(cfo_paragraphs) > 0:\n",
    "            x = bert_batch_predict(cfo_paragraphs)\n",
    "            x = [float(v) for v in x]\n",
    "            v['_cfo_sentiments'] = x\n",
    "            v['_cfo_avg_sentiment'] = float(np.mean(x))\n",
    "            v['_cfo_median_sentiment'] = float(np.median(x))\n",
    "            v['_cfo_min_sentiment'] = float(np.min(x))\n",
    "            v['_cfo_max_sentiment'] = float(np.max(x))\n",
    "        \n",
    "    except:\n",
    "        # print(f\"couldn't find paragraph or participant for {k}\")\n",
    "        counter += 1\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3477979",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../extract_data_scripts/training_earning_call_transcript_structured_with_sentiment.json\", \"w\") as fp:\n",
    "    json.dump(training_earning_call_transcript_structured, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12173104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 18/163 [00:24<03:25,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ceo cfo speak found for BMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 25/163 [00:32<02:41,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ceo cfo speak found for BB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 154/163 [03:33<00:13,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ceo cfo speak found for XFLT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 161/163 [03:43<00:03,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ceo cfo speak found for ARGX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [03:43<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for k, v in tqdm(validation_earning_call_transcript_structured.items()):\n",
    "    try:\n",
    "        paragraphs = v['paragraphs']\n",
    "        participants = v['participants']\n",
    "        \n",
    "        if not participants:\n",
    "            # print(f\"participant empty for {k}\")\n",
    "            counter += 1\n",
    "            continue\n",
    "        \n",
    "        v['_participants'] = {k: canonicalize(v) for k, v in participants.items()}\n",
    "        \n",
    "        if 'CEO' not in v['_participants']:\n",
    "            if 'CFO' not in v['_participants']:\n",
    "                counter += 1\n",
    "                continue\n",
    "                # print(f\"couldn't find CEO/CFO participant for {k}\")\n",
    "                # print(participants)\n",
    "        \n",
    "        ceo_paragraphs = []\n",
    "        cfo_paragraphs = []\n",
    "        for item in paragraphs:\n",
    "            speaker = item['speaker']\n",
    "            if v['_participants'].get(speaker) == 'CEO':\n",
    "                ceo_paragraphs.append(item['text'])\n",
    "            if v['_participants'].get(speaker) == 'CFO':\n",
    "                cfo_paragraphs.append(item['text'])\n",
    "        \n",
    "        if len(ceo_paragraphs) == 0:\n",
    "            if len(cfo_paragraphs) == 0:\n",
    "                counter += 1\n",
    "                print(f\"no ceo cfo speak found for {k}\")\n",
    "                continue\n",
    "                \n",
    "        v['_ceo_paragraphs'] = ceo_paragraphs\n",
    "        v['_cfo_paragraphs'] = cfo_paragraphs\n",
    "        \n",
    "        if len(ceo_paragraphs) > 0:\n",
    "            x = bert_batch_predict(ceo_paragraphs)\n",
    "            x = [float(v) for v in x]\n",
    "            v['_ceo_sentiments'] = x\n",
    "            v['_ceo_avg_sentiment'] = float(np.mean(x))\n",
    "            v['_ceo_median_sentiment'] = float(np.median(x))\n",
    "            v['_ceo_min_sentiment'] = float(np.min(x))\n",
    "            v['_ceo_max_sentiment'] = float(np.max(x))\n",
    "        \n",
    "        if len(cfo_paragraphs) > 0:\n",
    "            x = bert_batch_predict(cfo_paragraphs)\n",
    "            x = [float(v) for v in x]\n",
    "            v['_cfo_sentiments'] = x\n",
    "            v['_cfo_avg_sentiment'] = float(np.mean(x))\n",
    "            v['_cfo_median_sentiment'] = float(np.median(x))\n",
    "            v['_cfo_min_sentiment'] = float(np.min(x))\n",
    "            v['_cfo_max_sentiment'] = float(np.max(x))\n",
    "        \n",
    "    except:\n",
    "        # print(f\"couldn't find paragraph or participant for {k}\")\n",
    "        counter += 1\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63c85f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../extract_data_scripts/validation_earning_call_transcript_structured_with_sentiment.json\", \"w\") as fp:\n",
    "    json.dump(validation_earning_call_transcript_structured, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b96a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
