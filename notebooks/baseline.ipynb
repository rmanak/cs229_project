{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22d502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9ae71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654219da",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n",
    "                                    untar=True, cache_dir='.',\n",
    "                                    cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0cef11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README', 'train', 'test', 'imdb.vocab', 'imdbEr.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(dataset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef2084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, pos_files = next(os.walk(\"./aclImdb/train/pos/\"))\n",
    "_, _, neg_files = next(os.walk(\"./aclImdb/train/neg/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a020dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_corpus = []\n",
    "for fname in pos_files:\n",
    "    with open(\"./aclImdb/train/pos/\" + fname) as f:\n",
    "        text = f.read()\n",
    "        pos_corpus.append(text)\n",
    "\n",
    "pos_labels = [1] * len(pos_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d667ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_corpus = []\n",
    "for fname in neg_files:\n",
    "    with open(\"./aclImdb/train/neg/\" + fname) as f:\n",
    "        text = f.read()\n",
    "        neg_corpus.append(text)\n",
    "\n",
    "neg_labels = [0] * len(neg_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5bdea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"text\": pos_corpus + neg_corpus, \"label\": pos_labels + neg_labels})\n",
    "df = df.sample(frac=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38654c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24881</th>\n",
       "      <td>because you can put it on fast forward and wat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22691</th>\n",
       "      <td>I picked up this movie in the hope it would be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20307</th>\n",
       "      <td>This budget-starved Italian action/sci-fi hybr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>Farrah Fawcett gives the best performance by a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15540</th>\n",
       "      <td>Right away, this film was ridiculous. Not that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "24881  because you can put it on fast forward and wat...      0\n",
       "22691  I picked up this movie in the hope it would be...      0\n",
       "20307  This budget-starved Italian action/sci-fi hybr...      0\n",
       "8672   Farrah Fawcett gives the best performance by a...      1\n",
       "15540  Right away, this film was ridiculous. Not that...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa4216f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class one average 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"class one average\", np.mean(df[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9453b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# token_pattern = re.compile(r\"\\b\\w\\w+\\b\")\n",
    "# token_pattern.findall(\"this is! great() so more(inside)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c85ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(input_text: str) -> str:\n",
    "    s = input_text.lower()\n",
    "    s = s.replace('<br />', ' ')\n",
    "    return s\n",
    "    # return token_pattern.findall(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc0eddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = tf.keras.preprocessing.text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a81016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8da8b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], \n",
    "    df[\"label\"], \n",
    "    test_size=0.2,\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2161a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.fit_on_texts(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1817b985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80217"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok.word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a908a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tok.texts_to_sequences(text_train)\n",
    "X_test = tok.texts_to_sequences(text_test)\n",
    "\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=512, padding=\"post\")\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=512, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed7a3554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 512, 16)           1283488   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512, 16)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 16)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1283505 (4.90 MB)\n",
      "Trainable params: 1283505 (4.90 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Embedding(input_dim=len(tok.index_word) + 1, output_dim=16, input_length=512),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7718013",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a8bcb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 85s 134ms/step - loss: 0.6785 - binary_accuracy: 0.6372 - val_loss: 0.6501 - val_binary_accuracy: 0.7570\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.6016 - binary_accuracy: 0.7840 - val_loss: 0.5526 - val_binary_accuracy: 0.8100\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.5057 - binary_accuracy: 0.8317 - val_loss: 0.4719 - val_binary_accuracy: 0.8426\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.4290 - binary_accuracy: 0.8616 - val_loss: 0.4129 - val_binary_accuracy: 0.8618\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 12s 20ms/step - loss: 0.3716 - binary_accuracy: 0.8802 - val_loss: 0.3714 - val_binary_accuracy: 0.8730\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.3297 - binary_accuracy: 0.8965 - val_loss: 0.3417 - val_binary_accuracy: 0.8806\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.2961 - binary_accuracy: 0.9065 - val_loss: 0.3197 - val_binary_accuracy: 0.8854\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.2692 - binary_accuracy: 0.9139 - val_loss: 0.3058 - val_binary_accuracy: 0.8896\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.2465 - binary_accuracy: 0.9202 - val_loss: 0.2911 - val_binary_accuracy: 0.8916\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.2271 - binary_accuracy: 0.9258 - val_loss: 0.2818 - val_binary_accuracy: 0.8952\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.2104 - binary_accuracy: 0.9326 - val_loss: 0.2750 - val_binary_accuracy: 0.8956\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 3s 6ms/step - loss: 0.1937 - binary_accuracy: 0.9384 - val_loss: 0.2718 - val_binary_accuracy: 0.8950\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.1811 - binary_accuracy: 0.9429 - val_loss: 0.2635 - val_binary_accuracy: 0.9022\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.1676 - binary_accuracy: 0.9477 - val_loss: 0.2596 - val_binary_accuracy: 0.9034\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.1566 - binary_accuracy: 0.9514 - val_loss: 0.2574 - val_binary_accuracy: 0.9028\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.1452 - binary_accuracy: 0.9550 - val_loss: 0.2558 - val_binary_accuracy: 0.9040\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 3s 6ms/step - loss: 0.1355 - binary_accuracy: 0.9582 - val_loss: 0.2554 - val_binary_accuracy: 0.9018\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.1259 - binary_accuracy: 0.9618 - val_loss: 0.2546 - val_binary_accuracy: 0.9042\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1176 - binary_accuracy: 0.9658 - val_loss: 0.2550 - val_binary_accuracy: 0.9062\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1104 - binary_accuracy: 0.9671 - val_loss: 0.2558 - val_binary_accuracy: 0.9048\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f44a52a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tok.texts_to_sequences(text_train)\n",
    "X_test = tok.texts_to_sequences(text_test)\n",
    "\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=128, padding=\"post\")\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=128, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d659551e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 128, 64)           5133952   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128, 64)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5167041 (19.71 MB)\n",
      "Trainable params: 5167041 (19.71 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Embedding(input_dim=len(tok.index_word) + 1, output_dim=64, input_length=128),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(64, return_sequences=False),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d058c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cdeef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 54s 83ms/step - loss: 0.4492 - binary_accuracy: 0.7851 - val_loss: 0.3280 - val_binary_accuracy: 0.8654\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 13s 21ms/step - loss: 0.2164 - binary_accuracy: 0.9215 - val_loss: 0.3148 - val_binary_accuracy: 0.8706\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.1215 - binary_accuracy: 0.9592 - val_loss: 0.3586 - val_binary_accuracy: 0.8658\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.1876 - binary_accuracy: 0.9241 - val_loss: 0.6279 - val_binary_accuracy: 0.7478\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 0.1026 - binary_accuracy: 0.9678 - val_loss: 0.5689 - val_binary_accuracy: 0.8574\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1477 - binary_accuracy: 0.9412 - val_loss: 0.6084 - val_binary_accuracy: 0.6942\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1100 - binary_accuracy: 0.9614 - val_loss: 0.5054 - val_binary_accuracy: 0.8488\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.0389 - binary_accuracy: 0.9894 - val_loss: 0.5267 - val_binary_accuracy: 0.8520\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.0287 - binary_accuracy: 0.9934 - val_loss: 0.5763 - val_binary_accuracy: 0.8514\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.0441 - binary_accuracy: 0.9884 - val_loss: 0.6082 - val_binary_accuracy: 0.8448\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 0.0405 - binary_accuracy: 0.9898 - val_loss: 0.6307 - val_binary_accuracy: 0.8466\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.0207 - binary_accuracy: 0.9955 - val_loss: 0.6873 - val_binary_accuracy: 0.8444\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 0.0268 - binary_accuracy: 0.9943 - val_loss: 0.6572 - val_binary_accuracy: 0.8464\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.1033 - binary_accuracy: 0.9621 - val_loss: 0.5975 - val_binary_accuracy: 0.8060\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 0.1455 - binary_accuracy: 0.9508 - val_loss: 0.6757 - val_binary_accuracy: 0.8418\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.0390 - binary_accuracy: 0.9904 - val_loss: 0.6809 - val_binary_accuracy: 0.8450\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.0191 - binary_accuracy: 0.9954 - val_loss: 0.7043 - val_binary_accuracy: 0.8430\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.0263 - binary_accuracy: 0.9936 - val_loss: 0.7913 - val_binary_accuracy: 0.8410\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.0292 - binary_accuracy: 0.9924 - val_loss: 0.7326 - val_binary_accuracy: 0.8428\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.0138 - binary_accuracy: 0.9967 - val_loss: 0.7771 - val_binary_accuracy: 0.8440\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60900d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
