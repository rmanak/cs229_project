{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46427bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b5d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0f74a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773c56bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14149</td>\n",
       "      <td>I had two reasons for watching this swashbuckl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8946</td>\n",
       "      <td>This is, in my opinion, a very good film, espe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22378</td>\n",
       "      <td>I knew this film was supposed to be so bad it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12162</td>\n",
       "      <td>When the US entered World War I, the governmen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4879</td>\n",
       "      <td>Few movies can be viewed almost 60 years later...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  label\n",
       "0       14149  I had two reasons for watching this swashbuckl...      0\n",
       "1        8946  This is, in my opinion, a very good film, espe...      1\n",
       "2       22378  I knew this film was supposed to be so bad it ...      0\n",
       "3       12162  When the US entered World War I, the governmen...      1\n",
       "4        4879  Few movies can be viewed almost 60 years later...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure you run the baseline notebook that prepares this data\n",
    "# from the original imdb dataset downloaded from the web.\n",
    "df = pd.read_csv(\"./imdb_full_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7487e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class one average 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"class one average\", np.mean(df[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a78cbc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading glove vector from the web to local:\n",
    "# this may take a while\n",
    "# inside of this there is only 1 file\n",
    "# glove.42B.300d.txt\n",
    "# according to the website:https://nlp.stanford.edu/projects/glove/ \n",
    "# this one is uncased. \n",
    "\n",
    "# PLEASE MAKE SURE YOU UNCOMMENT AND RUN THE \n",
    "# COMMAND BELOW WHEN RUNNING THE NOTEBOOK FOR \n",
    "# THE FIRST TIME OR REST OF NOTEBOOK WON'T WORK\n",
    "\n",
    "# !wget https://nlp.stanford.edu/data/glove.42B.300d.zip ./glove.42B.300d.zip\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d85cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once downloaded unzip the file\n",
    "# !unzip glove.42B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f69a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also download other variations\n",
    "# I downloaded this one in particular seems like it\n",
    "# has various dimension sizes 50D, 100D etc...\n",
    "# inside of it there are 4 files:\n",
    "# glove.6B.100d.txt\n",
    "# glove.6B.200d.txt\n",
    "# glove.6B.300d.txt\n",
    "# glove.6B.50d.txt\n",
    "\n",
    "# WE MAY EXPERIMENT WITH SMALLER VECS LATER\n",
    "# FOR NOW WE DON'T NEED TO DOWNLOAD THIS ONE\n",
    "\n",
    "# !wget https://nlp.stanford.edu/data/glove.6B.zip ./glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b997d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb\t\t   glove.42B.300d.txt  glove_vecs.bin\r\n",
      "aclImdb_v1.tar.gz  glove.42B.300d.zip  imdb_full_dataset.csv\r\n",
      "baseline.ipynb\t   glove.6B.zip        using_glove.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "# check `glove.42B.300d.txt` and `imdb_full_dataset.csv` exists or see above comments \n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7705f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading glove vectors into dictionary of word -> vec\n",
    "# this may take a while for first run, once run\n",
    "# it will cache to a local pickle file and will run faster\n",
    "\n",
    "def _get_glove_index_dict(unzipped_file=\"glove.42B.300d.txt\"):\n",
    "    _LOCAL_FILE = \"./glove_vecs.bin\"\n",
    "    local_file = Path(_LOCAL_FILE)\n",
    "    \n",
    "    if local_file.is_file():\n",
    "        with open(_LOCAL_FILE, \"rb\") as fp:\n",
    "            glove_index = pickle.load(fp)\n",
    "        \n",
    "        return glove_index\n",
    "    \n",
    "    glove_index = OrderedDict()\n",
    "    \n",
    "    with open(unzipped_file) as fp:\n",
    "        for line in fp.read().splitlines():\n",
    "            values = line.split(\" \")\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "            glove_index[word] = coefs\n",
    "    \n",
    "    with open(_LOCAL_FILE, 'wb') as fp:\n",
    "        pickle.dump(glove_index, fp, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return glove_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c337aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_index = _get_glove_index_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5083eb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num unique words in glove 1917494\n"
     ]
    }
   ],
   "source": [
    "print(\"num unique words in glove\", len(glove_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4def55fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(input_text: str) -> str:\n",
    "    s = input_text.lower()\n",
    "    s = (s\n",
    "         .replace('<br />', ' ')\n",
    "         .replace('`', \"'\")\n",
    "         .replace('´',\"'\")\n",
    "         .replace(\" '\", ' \"')\n",
    "         .replace(\"-\", \" - \")\n",
    "         .replace(\"/\", \" \")\n",
    "         .replace(\"_\", \" \")\n",
    "        )\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbc955e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].map(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73626f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_func = nltk.word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e68059a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize_and_create_embedding_matrix(corpus, glove_index, tok_func, max_vocab=300000):\n",
    "    \n",
    "    token_dict = Counter()\n",
    "    for text in corpus:\n",
    "        tokens = tok_func(text)\n",
    "        token_dict.update(tokens)\n",
    "    \n",
    "    print(f\"found {len(token_dict)} unique tokens in corpus\")\n",
    "    \n",
    "    tokens_glove = Counter()\n",
    "    glove_oov = Counter()\n",
    "    \n",
    "    for k, v in token_dict.items():\n",
    "        if k in glove_index:\n",
    "            tokens_glove[k] = v\n",
    "        else:\n",
    "            glove_oov[k] = v\n",
    "    \n",
    "    print(f\"{len(tokens_glove)} of them are in glove\")\n",
    "    \n",
    "    vocab_counts = tokens_glove.most_common(max_vocab)\n",
    "    \n",
    "    vocabulary_index = {}\n",
    "    \n",
    "    for index, tup in enumerate(vocab_counts):\n",
    "        word, _ = tup\n",
    "        # 1 index is reserved for OOV\n",
    "        # 0 index is reserved for padding\n",
    "        vocabulary_index[word] = index + 2\n",
    "    \n",
    "    num_words = len(vocabulary_index) + 2\n",
    "    \n",
    "    # need to change this if other dim glove vecs are used\n",
    "    embedding_dim = 300 \n",
    "    embedding_matrix = np.random.uniform(-0.05, 0.05, size=(num_words, embedding_dim))\n",
    "    \n",
    "    embedding_matrix[0] = np.zeros(embedding_dim)\n",
    "    \n",
    "    for word, i in vocabulary_index.items():\n",
    "        embedding_vector = glove_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            # count the number of words not in embeddings_index\n",
    "            raise ValueError(\"impossible!\")\n",
    "    \n",
    "    return embedding_matrix, vocabulary_index, num_words, glove_oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b526740f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 80668 unique tokens in corpus\n",
      "70393 of them are in glove\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix, vocabulary_index, num_words, glove_oov = _tokenize_and_create_embedding_matrix(\n",
    "    df[\"text\"], \n",
    "    glove_index, \n",
    "    tokenizer_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6947c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70395\n"
     ]
    }
   ],
   "source": [
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1a5f736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('*', 7061), ('..', 1624), ('\\x96', 1338), ('......', 126), ('.......', 67), ('.the', 58), ('\\x97', 55), (\"'the\", 42), ('........', 40), ('hackenstein', 30), ('mraovich', 28), ('.i', 24), ('.........', 23), ('a+', 22), ('b+', 21), ('hundstage', 21), ('protée', 20), ('maléfique', 19), ('.it', 19), ('volckman', 18), ('...........', 18), ('burgade', 18), ('\\x8ei\\x9eek', 18), ('.but', 16), ('..........', 15), ('soutendijk', 15), ('d+', 15), ('firode', 15), ('danelia', 14), ('·', 14), ('no.1', 13), ('1973.', 13), ('mcdoakes', 13), ('guetary', 13), ('scuddamore', 13), ('1971.', 13), ('.there', 12), ('bressart', 12), ('1959.', 12), ('polarisdib', 12), ('lassick', 12), (\"rock'n'roll\", 12), ('venantini', 12), ('mcphillip', 12), ('1979.', 11), ('goyokin', 11), ('1969.', 11), ('sjoman', 11), ('\\x95', 11), ('unisols', 11), (\"k'sun\", 11), ('.............', 11), (\"did'nt\", 11), ('summersisle', 11), ('\\x91the', 11), ('tetsurô', 11), ('pâquerette', 10), ('hickcock', 10), ('gwizdo', 10), ('yonica', 10), ('milyang', 10), ('arzenta', 10), ('thornway', 10), ('£1', 10), ('20+', 10), ('strombel', 10), ('schizophreniac', 10), ('tollinger', 10), ('floraine', 10), ('screweyes', 9), ('3000.', 9), ('coulardeau', 9), ('1976.', 9), ('macchesney', 9), ('1978.', 9), ('1965.', 9), ('1972.', 9), ('machaty', 9), ('tatsuhito', 9), ('kopins', 8), ('1948.', 8), ('1977.', 8), ('buchfellner', 8), ('livien', 8), (\"does'nt\", 8), ('bhaiyyaji', 8), ('brommel', 8), ('.this', 8), ('bragana', 8), ('gadgetmobile', 8), ('meyerling', 8), ('1967.', 8), ('rosenlski', 8), ('s.i.c.k', 8), ('kosleck', 8), ('sontee', 8), ('rataud', 7), ('1968.', 7), ('............', 7), ('komizu', 7)]\n"
     ]
    }
   ],
   "source": [
    "print(glove_oov.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2b7176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_sequences(corpus, vocabulary_index, tok_func):\n",
    "    corpus_tokens = []\n",
    "    for text in corpus:\n",
    "        tokens = tok_func(text)\n",
    "        indicies = [vocabulary_index.get(x, 1) for x in tokens]\n",
    "        corpus_tokens.append(indicies)\n",
    "    return corpus_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88efa349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89f653a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], \n",
    "    df[\"label\"], \n",
    "    test_size=0.2,\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f31d43e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = texts_to_sequences(text_train, vocabulary_index, tokenizer_func)\n",
    "X_test = texts_to_sequences(text_test, vocabulary_index, tokenizer_func)\n",
    "\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=512)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af185e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 512, 300)          21118500  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512, 300)          0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512, 16)           4816      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512, 16)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 16)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21123333 (80.58 MB)\n",
      "Trainable params: 21123333 (80.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Embedding(input_dim=num_words, \n",
    "                     output_dim=300, \n",
    "                     input_length=512, \n",
    "                     weights=[embedding_matrix], \n",
    "                     trainable=True),\n",
    "    layers.Dropout(0.9),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(1, activation=\"sigmoid\")]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a407d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses.BinaryCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5e9520e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "40/40 [==============================] - 11s 242ms/step - loss: 0.6907 - binary_accuracy: 0.5343 - val_loss: 0.6813 - val_binary_accuracy: 0.5268\n",
      "Epoch 2/80\n",
      "40/40 [==============================] - 9s 235ms/step - loss: 0.6750 - binary_accuracy: 0.6043 - val_loss: 0.6617 - val_binary_accuracy: 0.6470\n",
      "Epoch 3/80\n",
      "40/40 [==============================] - 9s 220ms/step - loss: 0.6547 - binary_accuracy: 0.6486 - val_loss: 0.6314 - val_binary_accuracy: 0.7210\n",
      "Epoch 4/80\n",
      "40/40 [==============================] - 7s 186ms/step - loss: 0.6238 - binary_accuracy: 0.6934 - val_loss: 0.5974 - val_binary_accuracy: 0.7162\n",
      "Epoch 5/80\n",
      "40/40 [==============================] - 8s 191ms/step - loss: 0.5913 - binary_accuracy: 0.7152 - val_loss: 0.5578 - val_binary_accuracy: 0.7736\n",
      "Epoch 6/80\n",
      "40/40 [==============================] - 8s 197ms/step - loss: 0.5550 - binary_accuracy: 0.7488 - val_loss: 0.5206 - val_binary_accuracy: 0.7940\n",
      "Epoch 7/80\n",
      "40/40 [==============================] - 7s 180ms/step - loss: 0.5207 - binary_accuracy: 0.7766 - val_loss: 0.4857 - val_binary_accuracy: 0.8144\n",
      "Epoch 8/80\n",
      "40/40 [==============================] - 6s 158ms/step - loss: 0.4866 - binary_accuracy: 0.7972 - val_loss: 0.4536 - val_binary_accuracy: 0.8278\n",
      "Epoch 9/80\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.4562 - binary_accuracy: 0.8148 - val_loss: 0.4257 - val_binary_accuracy: 0.8382\n",
      "Epoch 10/80\n",
      "40/40 [==============================] - 6s 158ms/step - loss: 0.4302 - binary_accuracy: 0.8257 - val_loss: 0.4020 - val_binary_accuracy: 0.8504\n",
      "Epoch 11/80\n",
      "40/40 [==============================] - 6s 141ms/step - loss: 0.4108 - binary_accuracy: 0.8360 - val_loss: 0.3830 - val_binary_accuracy: 0.8566\n",
      "Epoch 12/80\n",
      "40/40 [==============================] - 6s 147ms/step - loss: 0.3890 - binary_accuracy: 0.8457 - val_loss: 0.3672 - val_binary_accuracy: 0.8648\n",
      "Epoch 13/80\n",
      "40/40 [==============================] - 5s 130ms/step - loss: 0.3722 - binary_accuracy: 0.8533 - val_loss: 0.3532 - val_binary_accuracy: 0.8692\n",
      "Epoch 14/80\n",
      "40/40 [==============================] - 5s 130ms/step - loss: 0.3585 - binary_accuracy: 0.8565 - val_loss: 0.3423 - val_binary_accuracy: 0.8732\n",
      "Epoch 15/80\n",
      "40/40 [==============================] - 5s 135ms/step - loss: 0.3439 - binary_accuracy: 0.8659 - val_loss: 0.3332 - val_binary_accuracy: 0.8764\n",
      "Epoch 16/80\n",
      "40/40 [==============================] - 5s 130ms/step - loss: 0.3314 - binary_accuracy: 0.8702 - val_loss: 0.3249 - val_binary_accuracy: 0.8796\n",
      "Epoch 17/80\n",
      "40/40 [==============================] - 6s 141ms/step - loss: 0.3196 - binary_accuracy: 0.8766 - val_loss: 0.3183 - val_binary_accuracy: 0.8810\n",
      "Epoch 18/80\n",
      "40/40 [==============================] - 4s 107ms/step - loss: 0.3055 - binary_accuracy: 0.8818 - val_loss: 0.3115 - val_binary_accuracy: 0.8826\n",
      "Epoch 19/80\n",
      "40/40 [==============================] - 4s 96ms/step - loss: 0.2976 - binary_accuracy: 0.8859 - val_loss: 0.3062 - val_binary_accuracy: 0.8844\n",
      "Epoch 20/80\n",
      "40/40 [==============================] - 4s 113ms/step - loss: 0.2891 - binary_accuracy: 0.8900 - val_loss: 0.3019 - val_binary_accuracy: 0.8858\n",
      "Epoch 21/80\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.2854 - binary_accuracy: 0.8906 - val_loss: 0.2975 - val_binary_accuracy: 0.8872\n",
      "Epoch 22/80\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2742 - binary_accuracy: 0.8945 - val_loss: 0.2938 - val_binary_accuracy: 0.8878\n",
      "Epoch 23/80\n",
      "40/40 [==============================] - 4s 113ms/step - loss: 0.2702 - binary_accuracy: 0.8983 - val_loss: 0.2917 - val_binary_accuracy: 0.8886\n",
      "Epoch 24/80\n",
      "40/40 [==============================] - 4s 108ms/step - loss: 0.2600 - binary_accuracy: 0.9036 - val_loss: 0.2879 - val_binary_accuracy: 0.8908\n",
      "Epoch 25/80\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.2530 - binary_accuracy: 0.9061 - val_loss: 0.2853 - val_binary_accuracy: 0.8908\n",
      "Epoch 26/80\n",
      "40/40 [==============================] - 4s 93ms/step - loss: 0.2448 - binary_accuracy: 0.9078 - val_loss: 0.2830 - val_binary_accuracy: 0.8922\n",
      "Epoch 27/80\n",
      "40/40 [==============================] - 4s 102ms/step - loss: 0.2403 - binary_accuracy: 0.9104 - val_loss: 0.2813 - val_binary_accuracy: 0.8918\n",
      "Epoch 28/80\n",
      "40/40 [==============================] - 4s 96ms/step - loss: 0.2360 - binary_accuracy: 0.9130 - val_loss: 0.2796 - val_binary_accuracy: 0.8922\n",
      "Epoch 29/80\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.2300 - binary_accuracy: 0.9121 - val_loss: 0.2781 - val_binary_accuracy: 0.8930\n",
      "Epoch 30/80\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2259 - binary_accuracy: 0.9169 - val_loss: 0.2768 - val_binary_accuracy: 0.8930\n",
      "Epoch 31/80\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 0.2175 - binary_accuracy: 0.9179 - val_loss: 0.2756 - val_binary_accuracy: 0.8918\n",
      "Epoch 32/80\n",
      "40/40 [==============================] - 4s 108ms/step - loss: 0.2166 - binary_accuracy: 0.9194 - val_loss: 0.2745 - val_binary_accuracy: 0.8926\n",
      "Epoch 33/80\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.2148 - binary_accuracy: 0.9202 - val_loss: 0.2747 - val_binary_accuracy: 0.8916\n",
      "Epoch 34/80\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.2079 - binary_accuracy: 0.9241 - val_loss: 0.2732 - val_binary_accuracy: 0.8942\n",
      "Epoch 35/80\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.2036 - binary_accuracy: 0.9254 - val_loss: 0.2725 - val_binary_accuracy: 0.8940\n",
      "Epoch 36/80\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.1999 - binary_accuracy: 0.9244 - val_loss: 0.2722 - val_binary_accuracy: 0.8950\n",
      "Epoch 37/80\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.1948 - binary_accuracy: 0.9272 - val_loss: 0.2717 - val_binary_accuracy: 0.8942\n",
      "Epoch 38/80\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.1893 - binary_accuracy: 0.9297 - val_loss: 0.2716 - val_binary_accuracy: 0.8942\n",
      "Epoch 39/80\n",
      "40/40 [==============================] - 3s 69ms/step - loss: 0.1874 - binary_accuracy: 0.9304 - val_loss: 0.2715 - val_binary_accuracy: 0.8958\n",
      "Epoch 40/80\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.1843 - binary_accuracy: 0.9327 - val_loss: 0.2715 - val_binary_accuracy: 0.8958\n",
      "Epoch 41/80\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1819 - binary_accuracy: 0.9330 - val_loss: 0.2713 - val_binary_accuracy: 0.8960\n",
      "Epoch 42/80\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.1784 - binary_accuracy: 0.9359 - val_loss: 0.2713 - val_binary_accuracy: 0.8966\n",
      "Epoch 43/80\n",
      "40/40 [==============================] - 3s 62ms/step - loss: 0.1744 - binary_accuracy: 0.9369 - val_loss: 0.2712 - val_binary_accuracy: 0.8966\n",
      "Epoch 44/80\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.1709 - binary_accuracy: 0.9389 - val_loss: 0.2722 - val_binary_accuracy: 0.8964\n",
      "Epoch 45/80\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.1700 - binary_accuracy: 0.9374 - val_loss: 0.2718 - val_binary_accuracy: 0.8978\n",
      "Epoch 46/80\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1653 - binary_accuracy: 0.9384 - val_loss: 0.2724 - val_binary_accuracy: 0.8974\n",
      "Epoch 47/80\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.1649 - binary_accuracy: 0.9385 - val_loss: 0.2725 - val_binary_accuracy: 0.8986\n",
      "Epoch 48/80\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1591 - binary_accuracy: 0.9404 - val_loss: 0.2725 - val_binary_accuracy: 0.8982\n",
      "Epoch 49/80\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1580 - binary_accuracy: 0.9430 - val_loss: 0.2727 - val_binary_accuracy: 0.8992\n",
      "Epoch 50/80\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.1537 - binary_accuracy: 0.9431 - val_loss: 0.2730 - val_binary_accuracy: 0.8994\n",
      "Epoch 51/80\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1502 - binary_accuracy: 0.9451 - val_loss: 0.2740 - val_binary_accuracy: 0.8976\n",
      "Epoch 52/80\n",
      "40/40 [==============================] - 4s 85ms/step - loss: 0.1468 - binary_accuracy: 0.9479 - val_loss: 0.2743 - val_binary_accuracy: 0.8978\n",
      "Epoch 53/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 22ms/step - loss: 0.1442 - binary_accuracy: 0.9499 - val_loss: 0.2746 - val_binary_accuracy: 0.8974\n",
      "Epoch 54/80\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1453 - binary_accuracy: 0.9477 - val_loss: 0.2753 - val_binary_accuracy: 0.8982\n",
      "Epoch 55/80\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.1393 - binary_accuracy: 0.9494 - val_loss: 0.2759 - val_binary_accuracy: 0.8982\n",
      "Epoch 56/80\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.1402 - binary_accuracy: 0.9495 - val_loss: 0.2767 - val_binary_accuracy: 0.8986\n",
      "Epoch 57/80\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1368 - binary_accuracy: 0.9506 - val_loss: 0.2780 - val_binary_accuracy: 0.8994\n",
      "Epoch 58/80\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.1366 - binary_accuracy: 0.9509 - val_loss: 0.2787 - val_binary_accuracy: 0.8978\n",
      "Epoch 59/80\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.1384 - binary_accuracy: 0.9487 - val_loss: 0.2793 - val_binary_accuracy: 0.8978\n",
      "Epoch 60/80\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1307 - binary_accuracy: 0.9536 - val_loss: 0.2803 - val_binary_accuracy: 0.8974\n",
      "Epoch 61/80\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.1282 - binary_accuracy: 0.9540 - val_loss: 0.2814 - val_binary_accuracy: 0.8976\n",
      "Epoch 62/80\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1282 - binary_accuracy: 0.9540 - val_loss: 0.2820 - val_binary_accuracy: 0.8980\n",
      "Epoch 63/80\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1265 - binary_accuracy: 0.9556 - val_loss: 0.2832 - val_binary_accuracy: 0.8986\n",
      "Epoch 64/80\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.1235 - binary_accuracy: 0.9555 - val_loss: 0.2828 - val_binary_accuracy: 0.8990\n",
      "Epoch 65/80\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.1194 - binary_accuracy: 0.9561 - val_loss: 0.2843 - val_binary_accuracy: 0.8984\n",
      "Epoch 66/80\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.1227 - binary_accuracy: 0.9553 - val_loss: 0.2858 - val_binary_accuracy: 0.8996\n",
      "Epoch 67/80\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1208 - binary_accuracy: 0.9568 - val_loss: 0.2860 - val_binary_accuracy: 0.8990\n",
      "Epoch 68/80\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1170 - binary_accuracy: 0.9582 - val_loss: 0.2878 - val_binary_accuracy: 0.8986\n",
      "Epoch 69/80\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.1149 - binary_accuracy: 0.9593 - val_loss: 0.2882 - val_binary_accuracy: 0.8992\n",
      "Epoch 70/80\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.1102 - binary_accuracy: 0.9620 - val_loss: 0.2896 - val_binary_accuracy: 0.8992\n",
      "Epoch 71/80\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.1124 - binary_accuracy: 0.9590 - val_loss: 0.2910 - val_binary_accuracy: 0.8984\n",
      "Epoch 72/80\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1134 - binary_accuracy: 0.9588 - val_loss: 0.2926 - val_binary_accuracy: 0.8980\n",
      "Epoch 73/80\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1075 - binary_accuracy: 0.9604 - val_loss: 0.2930 - val_binary_accuracy: 0.8970\n",
      "Epoch 74/80\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.1089 - binary_accuracy: 0.9614 - val_loss: 0.2947 - val_binary_accuracy: 0.8976\n",
      "Epoch 75/80\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1063 - binary_accuracy: 0.9627 - val_loss: 0.2961 - val_binary_accuracy: 0.8974\n",
      "Epoch 76/80\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.1040 - binary_accuracy: 0.9636 - val_loss: 0.2976 - val_binary_accuracy: 0.8978\n",
      "Epoch 77/80\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1052 - binary_accuracy: 0.9624 - val_loss: 0.2980 - val_binary_accuracy: 0.8972\n",
      "Epoch 78/80\n",
      "40/40 [==============================] - 1s 16ms/step - loss: 0.0988 - binary_accuracy: 0.9653 - val_loss: 0.2999 - val_binary_accuracy: 0.8970\n",
      "Epoch 79/80\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.0961 - binary_accuracy: 0.9668 - val_loss: 0.2999 - val_binary_accuracy: 0.8966\n",
      "Epoch 80/80\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1001 - binary_accuracy: 0.9657 - val_loss: 0.3022 - val_binary_accuracy: 0.8976\n"
     ]
    }
   ],
   "source": [
    "epochs = 80\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c6be3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('vocab_index.json', 'w') as fp:\n",
    "    json.dump(vocabulary_index, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c60dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('glove_word_averaging_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cd93ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = texts_to_sequences(text_train, vocabulary_index, tokenizer_func)\n",
    "X_test = texts_to_sequences(text_test, vocabulary_index, tokenizer_func)\n",
    "\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=256)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e85f7dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 256, 300)          21118500  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256, 300)          0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256, 64)           19264     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256, 64)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21171845 (80.76 MB)\n",
      "Trainable params: 21171845 (80.76 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Embedding(input_dim=num_words, \n",
    "                     output_dim=300, \n",
    "                     input_length=256, \n",
    "                     weights=[embedding_matrix], \n",
    "                     trainable=True),\n",
    "    layers.Dropout(0.9),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.LSTM(64, return_sequences=False),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(1, activation=\"sigmoid\")]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c605c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses.BinaryCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08d2c39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "40/40 [==============================] - 13s 254ms/step - loss: 0.6961 - binary_accuracy: 0.4995 - val_loss: 0.6911 - val_binary_accuracy: 0.5422\n",
      "Epoch 2/80\n",
      "40/40 [==============================] - 9s 230ms/step - loss: 0.6922 - binary_accuracy: 0.5189 - val_loss: 0.6905 - val_binary_accuracy: 0.5148\n",
      "Epoch 3/80\n",
      "40/40 [==============================] - 8s 200ms/step - loss: 0.6873 - binary_accuracy: 0.5416 - val_loss: 0.6787 - val_binary_accuracy: 0.5412\n",
      "Epoch 4/80\n",
      "40/40 [==============================] - 9s 213ms/step - loss: 0.6577 - binary_accuracy: 0.6213 - val_loss: 0.6381 - val_binary_accuracy: 0.6308\n",
      "Epoch 5/80\n",
      "40/40 [==============================] - 8s 196ms/step - loss: 0.6166 - binary_accuracy: 0.6755 - val_loss: 0.5656 - val_binary_accuracy: 0.7202\n",
      "Epoch 6/80\n",
      "40/40 [==============================] - 7s 185ms/step - loss: 0.5523 - binary_accuracy: 0.7293 - val_loss: 0.4653 - val_binary_accuracy: 0.7966\n",
      "Epoch 7/80\n",
      "40/40 [==============================] - 7s 180ms/step - loss: 0.4949 - binary_accuracy: 0.7681 - val_loss: 0.4704 - val_binary_accuracy: 0.8022\n",
      "Epoch 8/80\n",
      "40/40 [==============================] - 6s 144ms/step - loss: 0.4585 - binary_accuracy: 0.7908 - val_loss: 0.4214 - val_binary_accuracy: 0.8138\n",
      "Epoch 9/80\n",
      "40/40 [==============================] - 6s 139ms/step - loss: 0.4270 - binary_accuracy: 0.8084 - val_loss: 0.4150 - val_binary_accuracy: 0.8166\n",
      "Epoch 10/80\n",
      "40/40 [==============================] - 6s 156ms/step - loss: 0.4039 - binary_accuracy: 0.8201 - val_loss: 0.3943 - val_binary_accuracy: 0.8280\n",
      "Epoch 11/80\n",
      "40/40 [==============================] - 6s 139ms/step - loss: 0.3823 - binary_accuracy: 0.8346 - val_loss: 0.3952 - val_binary_accuracy: 0.8204\n",
      "Epoch 12/80\n",
      "40/40 [==============================] - 6s 145ms/step - loss: 0.3595 - binary_accuracy: 0.8459 - val_loss: 0.3637 - val_binary_accuracy: 0.8366\n",
      "Epoch 13/80\n",
      "40/40 [==============================] - 5s 127ms/step - loss: 0.3396 - binary_accuracy: 0.8572 - val_loss: 0.3689 - val_binary_accuracy: 0.8396\n",
      "Epoch 14/80\n",
      "40/40 [==============================] - 6s 139ms/step - loss: 0.3295 - binary_accuracy: 0.8610 - val_loss: 0.3401 - val_binary_accuracy: 0.8522\n",
      "Epoch 15/80\n",
      "40/40 [==============================] - 4s 93ms/step - loss: 0.3184 - binary_accuracy: 0.8654 - val_loss: 0.3399 - val_binary_accuracy: 0.8508\n",
      "Epoch 16/80\n",
      "40/40 [==============================] - 5s 122ms/step - loss: 0.3024 - binary_accuracy: 0.8773 - val_loss: 0.3484 - val_binary_accuracy: 0.8520\n",
      "Epoch 17/80\n",
      "40/40 [==============================] - 5s 122ms/step - loss: 0.2949 - binary_accuracy: 0.8767 - val_loss: 0.3470 - val_binary_accuracy: 0.8438\n",
      "Epoch 18/80\n",
      "40/40 [==============================] - 4s 99ms/step - loss: 0.2868 - binary_accuracy: 0.8821 - val_loss: 0.3331 - val_binary_accuracy: 0.8574\n",
      "Epoch 19/80\n",
      "40/40 [==============================] - 4s 93ms/step - loss: 0.2705 - binary_accuracy: 0.8899 - val_loss: 0.3272 - val_binary_accuracy: 0.8686\n",
      "Epoch 20/80\n",
      "40/40 [==============================] - 4s 99ms/step - loss: 0.2716 - binary_accuracy: 0.8920 - val_loss: 0.3415 - val_binary_accuracy: 0.8488\n",
      "Epoch 21/80\n",
      "40/40 [==============================] - 4s 93ms/step - loss: 0.2625 - binary_accuracy: 0.8957 - val_loss: 0.3219 - val_binary_accuracy: 0.8650\n",
      "Epoch 22/80\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.2649 - binary_accuracy: 0.8925 - val_loss: 0.3376 - val_binary_accuracy: 0.8510\n",
      "Epoch 23/80\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.2539 - binary_accuracy: 0.8996 - val_loss: 0.3238 - val_binary_accuracy: 0.8680\n",
      "Epoch 24/80\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.2422 - binary_accuracy: 0.9033 - val_loss: 0.3230 - val_binary_accuracy: 0.8642\n",
      "Epoch 25/80\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.2364 - binary_accuracy: 0.9050 - val_loss: 0.3192 - val_binary_accuracy: 0.8708\n",
      "Epoch 26/80\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.2349 - binary_accuracy: 0.9100 - val_loss: 0.3152 - val_binary_accuracy: 0.8694\n",
      "Epoch 27/80\n",
      "40/40 [==============================] - 4s 99ms/step - loss: 0.2313 - binary_accuracy: 0.9099 - val_loss: 0.3196 - val_binary_accuracy: 0.8802\n",
      "Epoch 28/80\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.2206 - binary_accuracy: 0.9147 - val_loss: 0.3085 - val_binary_accuracy: 0.8842\n",
      "Epoch 29/80\n",
      "40/40 [==============================] - 3s 59ms/step - loss: 0.2137 - binary_accuracy: 0.9150 - val_loss: 0.3074 - val_binary_accuracy: 0.8778\n",
      "Epoch 30/80\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.2113 - binary_accuracy: 0.9179 - val_loss: 0.3014 - val_binary_accuracy: 0.8768\n",
      "Epoch 31/80\n",
      "40/40 [==============================] - 3s 87ms/step - loss: 0.2036 - binary_accuracy: 0.9198 - val_loss: 0.3000 - val_binary_accuracy: 0.8836\n",
      "Epoch 32/80\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.2007 - binary_accuracy: 0.9233 - val_loss: 0.3117 - val_binary_accuracy: 0.8776\n",
      "Epoch 33/80\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.1909 - binary_accuracy: 0.9283 - val_loss: 0.3007 - val_binary_accuracy: 0.8878\n",
      "Epoch 34/80\n",
      "40/40 [==============================] - 3s 58ms/step - loss: 0.1941 - binary_accuracy: 0.9254 - val_loss: 0.2978 - val_binary_accuracy: 0.8816\n",
      "Epoch 35/80\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1885 - binary_accuracy: 0.9276 - val_loss: 0.3023 - val_binary_accuracy: 0.8806\n",
      "Epoch 36/80\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1753 - binary_accuracy: 0.9341 - val_loss: 0.3032 - val_binary_accuracy: 0.8862\n",
      "Epoch 37/80\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1753 - binary_accuracy: 0.9333 - val_loss: 0.3034 - val_binary_accuracy: 0.8834\n",
      "Epoch 38/80\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1729 - binary_accuracy: 0.9334 - val_loss: 0.3026 - val_binary_accuracy: 0.8922\n",
      "Epoch 39/80\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1662 - binary_accuracy: 0.9380 - val_loss: 0.3071 - val_binary_accuracy: 0.8838\n",
      "Epoch 40/80\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.1662 - binary_accuracy: 0.9387 - val_loss: 0.3103 - val_binary_accuracy: 0.8770\n",
      "Epoch 41/80\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1631 - binary_accuracy: 0.9380 - val_loss: 0.3033 - val_binary_accuracy: 0.8902\n",
      "Epoch 42/80\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1551 - binary_accuracy: 0.9420 - val_loss: 0.3163 - val_binary_accuracy: 0.8824\n",
      "Epoch 43/80\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1555 - binary_accuracy: 0.9417 - val_loss: 0.2987 - val_binary_accuracy: 0.8922\n",
      "Epoch 44/80\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1440 - binary_accuracy: 0.9455 - val_loss: 0.3098 - val_binary_accuracy: 0.8862\n",
      "Epoch 45/80\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1477 - binary_accuracy: 0.9454 - val_loss: 0.3042 - val_binary_accuracy: 0.8862\n",
      "Epoch 46/80\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.1409 - binary_accuracy: 0.9481 - val_loss: 0.3099 - val_binary_accuracy: 0.8914\n",
      "Epoch 47/80\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1361 - binary_accuracy: 0.9498 - val_loss: 0.3251 - val_binary_accuracy: 0.8894\n",
      "Epoch 48/80\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1372 - binary_accuracy: 0.9485 - val_loss: 0.3254 - val_binary_accuracy: 0.8900\n",
      "Epoch 49/80\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1339 - binary_accuracy: 0.9509 - val_loss: 0.3046 - val_binary_accuracy: 0.8886\n",
      "Epoch 50/80\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.1321 - binary_accuracy: 0.9512 - val_loss: 0.3216 - val_binary_accuracy: 0.8902\n",
      "Epoch 51/80\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1259 - binary_accuracy: 0.9530 - val_loss: 0.3124 - val_binary_accuracy: 0.8890\n",
      "Epoch 52/80\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1203 - binary_accuracy: 0.9554 - val_loss: 0.3137 - val_binary_accuracy: 0.8892\n",
      "Epoch 53/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 41ms/step - loss: 0.1218 - binary_accuracy: 0.9546 - val_loss: 0.3208 - val_binary_accuracy: 0.8892\n",
      "Epoch 54/80\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.1173 - binary_accuracy: 0.9571 - val_loss: 0.3207 - val_binary_accuracy: 0.8892\n",
      "Epoch 55/80\n",
      "40/40 [==============================] - 3s 59ms/step - loss: 0.1158 - binary_accuracy: 0.9587 - val_loss: 0.3132 - val_binary_accuracy: 0.8892\n",
      "Epoch 56/80\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1117 - binary_accuracy: 0.9590 - val_loss: 0.3031 - val_binary_accuracy: 0.8908\n",
      "Epoch 57/80\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1130 - binary_accuracy: 0.9592 - val_loss: 0.3551 - val_binary_accuracy: 0.8860\n",
      "Epoch 58/80\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.1157 - binary_accuracy: 0.9589 - val_loss: 0.3262 - val_binary_accuracy: 0.8882\n",
      "Epoch 59/80\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1061 - binary_accuracy: 0.9623 - val_loss: 0.3231 - val_binary_accuracy: 0.8910\n",
      "Epoch 60/80\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1091 - binary_accuracy: 0.9608 - val_loss: 0.3441 - val_binary_accuracy: 0.8912\n",
      "Epoch 61/80\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1002 - binary_accuracy: 0.9637 - val_loss: 0.3419 - val_binary_accuracy: 0.8878\n",
      "Epoch 62/80\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.0994 - binary_accuracy: 0.9640 - val_loss: 0.3492 - val_binary_accuracy: 0.8878\n",
      "Epoch 63/80\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.0959 - binary_accuracy: 0.9658 - val_loss: 0.3355 - val_binary_accuracy: 0.8882\n",
      "Epoch 64/80\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.0948 - binary_accuracy: 0.9667 - val_loss: 0.3545 - val_binary_accuracy: 0.8890\n",
      "Epoch 65/80\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.0921 - binary_accuracy: 0.9668 - val_loss: 0.3495 - val_binary_accuracy: 0.8916\n",
      "Epoch 66/80\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.0913 - binary_accuracy: 0.9677 - val_loss: 0.3671 - val_binary_accuracy: 0.8890\n",
      "Epoch 67/80\n",
      "40/40 [==============================] - 3s 59ms/step - loss: 0.0912 - binary_accuracy: 0.9682 - val_loss: 0.3701 - val_binary_accuracy: 0.8906\n",
      "Epoch 68/80\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.0920 - binary_accuracy: 0.9660 - val_loss: 0.3346 - val_binary_accuracy: 0.8872\n",
      "Epoch 69/80\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0851 - binary_accuracy: 0.9696 - val_loss: 0.3569 - val_binary_accuracy: 0.8884\n",
      "Epoch 70/80\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.0873 - binary_accuracy: 0.9703 - val_loss: 0.3534 - val_binary_accuracy: 0.8908\n",
      "Epoch 71/80\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.0792 - binary_accuracy: 0.9721 - val_loss: 0.3450 - val_binary_accuracy: 0.8918\n",
      "Epoch 72/80\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.0835 - binary_accuracy: 0.9689 - val_loss: 0.3469 - val_binary_accuracy: 0.8890\n",
      "Epoch 73/80\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.0811 - binary_accuracy: 0.9717 - val_loss: 0.3529 - val_binary_accuracy: 0.8860\n",
      "Epoch 74/80\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0806 - binary_accuracy: 0.9713 - val_loss: 0.3690 - val_binary_accuracy: 0.8886\n",
      "Epoch 75/80\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.0762 - binary_accuracy: 0.9728 - val_loss: 0.3664 - val_binary_accuracy: 0.8894\n",
      "Epoch 76/80\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.0750 - binary_accuracy: 0.9739 - val_loss: 0.3733 - val_binary_accuracy: 0.8888\n",
      "Epoch 77/80\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.0792 - binary_accuracy: 0.9707 - val_loss: 0.3560 - val_binary_accuracy: 0.8908\n",
      "Epoch 78/80\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.0719 - binary_accuracy: 0.9745 - val_loss: 0.3790 - val_binary_accuracy: 0.8898\n",
      "Epoch 79/80\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.0728 - binary_accuracy: 0.9750 - val_loss: 0.3751 - val_binary_accuracy: 0.8888\n",
      "Epoch 80/80\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0656 - binary_accuracy: 0.9780 - val_loss: 0.3844 - val_binary_accuracy: 0.8914\n"
     ]
    }
   ],
   "source": [
    "epochs = 80\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "727cdc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('glove_lstm_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e36d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
